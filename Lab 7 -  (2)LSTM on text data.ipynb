{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    LSTM(  \n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 20s 127us/step - loss: 2.4435\n",
      "Generating from seed: out of his\n",
      "out of his and the said the said the said the said the said the said the said the said the said the said the s==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 146us/step - loss: 2.0139\n",
      "Generating from seed: gh all her\n",
      "gh all her and the said the said the said the said the said the said the said the said the said the said the s==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 149us/step - loss: 1.83070s - loss: 1.8\n",
      "Generating from seed: at ours th\n",
      "at ours the mouse the said the mouse the said the mouse the said the mouse the said the mouse the said the mou==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 145us/step - loss: 1.7082\n",
      "Generating from seed:  end, said\n",
      " end, said the gryphon and the warke of the warke of the warke of the warke of the warke of the warke of the w==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 146us/step - loss: 1.61840s - l\n",
      "Generating from seed: ought it w\n",
      "ought it was so the mouse the more the more the more the more the more the more the more the more the more the==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 148us/step - loss: 1.5472\n",
      "Generating from seed: e mock tur\n",
      "e mock turtle said the mock turtle said the mock turtle said the mock turtle said the mock turtle said the moc==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 146us/step - loss: 1.4887\n",
      "Generating from seed: ing, and p\n",
      "ing, and project gutenberg litered the project gutenberg litered the project gutenberg litered the project gut==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 150us/step - loss: 1.43950\n",
      "Generating from seed:  for two p\n",
      " for two persent to her said to herself the read and the more the dormouse the dormouse the dormouse the dormo==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 147us/step - loss: 1.3966\n",
      "Generating from seed: ty of sayi\n",
      "ty of saying to herself the reasented to the words and the reasented to the words and the reasented to the wor==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 151us/step - loss: 1.3606\n",
      "Generating from seed: lice. you \n",
      "lice. you may so she was so the mock turtle say the caterpillar some of the works in the work out a great hurr==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 25s 155us/step - loss: 1.3281\n",
      "Generating from seed: e had just\n",
      "e had just as she spoke at the end of the sald to the such a court of the selper the project gutenberg-tm elec==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 152us/step - loss: 1.3003\n",
      "Generating from seed: n replied \n",
      "n replied to the project gutenberg-tm electronic works in a long as it was a little beliens, and the mouse of ==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 153us/step - loss: 1.2741\n",
      "Generating from seed: ! it did s\n",
      "! it did so this time the dormouse the duchess that she was soon of the thing is the party a little shrill had==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 153us/step - loss: 1.2509\n",
      "Generating from seed: hen said t\n",
      "hen said this time the works and the mouse of the court in the seam, and the mouse of the court in the seam, a==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 152us/step - loss: 1.2295\n",
      "Generating from seed: there was \n",
      "there was a little before she was a little before she was a little before she was a little before she was a li==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 153us/step - loss: 1.2091\n",
      "Generating from seed: nds a good\n",
      "nds a good deal the mouse to see it was the mouse to see it was the mouse to see it was the mouse to see it wa==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 152us/step - loss: 1.1902\n",
      "Generating from seed: o was talk\n",
      "o was talking a little start of the reason in the dormouse she had not go any of the sel me like that she had ==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 25s 155us/step - loss: 1.1727 - ETA: 0s \n",
      "Generating from seed: , nibbling\n",
      ", nibbling at the words was a little start of the court. alice replied in a low to her face, when i cant to th==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 148us/step - loss: 1.1563\n",
      "Generating from seed: aw the moc\n",
      "aw the mock turtle was not cant like the roof of the court, and then she was a little shriek a carrouse the sa==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 151us/step - loss: 1.1401\n",
      "Generating from seed: t had lost\n",
      "t had lost the look of the salt was the baby with the little golden key to looked at the end of the soldiers w==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 148us/step - loss: 1.1259\n",
      "Generating from seed: e? i-- oh,\n",
      "e? i-- oh, i should be of coniast of the project gutenberg-tm electronic works in the sound of the trees of th==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 24s 149us/step - loss: 1.1110\n",
      "Generating from seed:  i will ju\n",
      " i will just as if he said to herself, and the mock turtle seemed to be a terms of the confish not a minute or==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 148us/step - loss: 1.0969\n",
      "Generating from seed: stions abo\n",
      "stions about the caterpillar thing to say this agreement, and the moral of the things and flompoled onf hand a==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 148us/step - loss: 1.0843\n",
      "Generating from seed: im sure th\n",
      "im sure this work is a large the party with the party with the party with the party with the party with the pa==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 23s 147us/step - loss: 1.0715\n",
      "Generating from seed:  that she \n",
      " that she was a little shriek at all as it was a little shriek at all as it was a little shriek at all as it w\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # For each iteration, run the model fitting procedure for a number of epochs.\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # For a number of prediction steps using the current version of the trained\n",
    "    # model, construct a one-hot encoding of the test input and append a prediction.\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # Here is the one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # Make a prediction with the current model.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # Print the prediction appended to the test example.\n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # Increment the test example to contain the prediction as if it\n",
    "        # were the correct next letter.\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

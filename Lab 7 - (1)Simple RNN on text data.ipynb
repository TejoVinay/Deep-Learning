{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQLEN, STEP = 10, 1\n",
    "input_chars, label_chars = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE, HIDDEN_SIZE = 128, 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    SimpleRNN(  \n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Tejo Vinay\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 4s 28us/step - loss: 2.3346\n",
      "Generating from seed: n. oh, you\n",
      "n. oh, you don the said the got in the sare the got in the sare the got in the sare the got in the sare the go==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 4s 25us/step - loss: 2.0473\n",
      "Generating from seed: n a very u\n",
      "n a very und be the tore the hed the mouthe would the the the the the the the the the the the the the the the ==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 4s 27us/step - loss: 1.9473\n",
      "Generating from seed: ied to spe\n",
      "ied to spees of the said the mack tur leat ous the was the was the was the was the was the was the was the was==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 39us/step - loss: 1.8679\n",
      "Generating from seed: used to qu\n",
      "used to queen the dont the was a dont the was a dont the was a dont the was a dont the was a dont the was a do==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 39us/step - loss: 1.8019\n",
      "Generating from seed: on. alice \n",
      "on. alice and the mack turtle said the king the mack turtle said the king the mack turtle said the king the ma==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 42us/step - loss: 1.7464\n",
      "Generating from seed:  somersaul\n",
      " somersaul the poor the cours the cours the cours the cours the cours the cours the cours the cours the cours ==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.6994\n",
      "Generating from seed: things bet\n",
      "things bet in the mouse of the mouse of the mouse of the mouse of the mouse of the mouse of the mouse of the m==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 43us/step - loss: 1.6606\n",
      "Generating from seed: rt is the \n",
      "rt is the distone the parter and the march her the right and the march her the right and the march her the rig==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 6s 41us/step - loss: 1.6268\n",
      "Generating from seed: ustody and\n",
      "ustody and she said the gryphon in a looked to she was not be on the gryphon in a looked to she was not be on ==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 43us/step - loss: 1.5987\n",
      "Generating from seed: hurt the p\n",
      "hurt the project gutenberg-tm electronic work it all the mors the cour down the cour down the cour down the co==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 42us/step - loss: 1.5736\n",
      "Generating from seed: re is anot\n",
      "re is another mees a contire she was not it was the reations and she said the dont be a contire she was not it==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 43us/step - loss: 1.5518\n",
      "Generating from seed: er sister \n",
      "er sister founder of the course for the rootman im and the mouse the rootman im and the mouse the rootman im a==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.5328\n",
      "Generating from seed: a, declare\n",
      "a, declared the dormouse the poor little distribution of the share it was so the mouse of the share it was so ==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.5154\n",
      "Generating from seed: n changed \n",
      "n changed to herself the cat said the caterpillar the cat said the caterpillar the cat said the caterpillar th==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.4999\n",
      "Generating from seed: t high, an\n",
      "t high, and the mouse the persers, and the mouse the persers, and the mouse the persers, and the mouse the per==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 43us/step - loss: 1.4866\n",
      "Generating from seed: n hastily.\n",
      "n hastily. alice thing her interpalice, and she was no hard a grow the dodmoned at they said the docresing to ==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 45us/step - loss: 1.4739\n",
      "Generating from seed: heir slate\n",
      "heir slates the duchess the putter and she said the mock turtle with a shared to her found the mock turtle wit==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.4629\n",
      "Generating from seed: me very wh\n",
      "me very which the mock turtle were the mock turtle were the mock turtle were the mock turtle were the mock tur==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 43us/step - loss: 1.4525\n",
      "Generating from seed: d-butter--\n",
      "d-butter--and the look the looking as i cant on the thatter the looking as i cant on the thatter the looking a==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 43us/step - loss: 1.4428\n",
      "Generating from seed: you mean t\n",
      "you mean the dormouse of the way of the way of the way of the way of the way of the way of the way of the way ==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 43us/step - loss: 1.4332\n",
      "Generating from seed:  her. she \n",
      " her. she could not in the seen the gryphon the project gutenberg-tm electronic work or any down the gryphon t==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 43us/step - loss: 1.4260\n",
      "Generating from seed: pecially c\n",
      "pecially care of the sort of the sort of the sort of the sort of the sort of the sort of the sort of the sort ==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.4184\n",
      "Generating from seed: ens and wr\n",
      "ens and write the the the the the the the the the the the the the the the the the the the the the the the the ==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 45us/step - loss: 1.4110\n",
      "Generating from seed:  the queen\n",
      " the queen of the tanch hare all the tay the march hare arm the cate of the caterpillar that the mock turtle s==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 7s 44us/step - loss: 1.4047\n",
      "Generating from seed: did they l\n",
      "did they look as she could not stily as she came the little shared to her for a more to herself, and the littl\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # For each iteration, run the model fitting procedure for a number of epochs.\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # For a number of prediction steps using the current version of the trained\n",
    "    # model, construct a one-hot encoding of the test input and append a prediction.\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # Here is the one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # Make a prediction with the current model.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # Print the prediction appended to the test example.\n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # Increment the test example to contain the prediction as if it\n",
    "        # were the correct next letter.\n",
    "        test_chars = test_chars[1:] + y_pred\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
